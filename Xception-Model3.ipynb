{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Necessary Import Modules****"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\nimport glob\nimport cv2\nimport json\nimport glob\nimport torch\nfrom tqdm import tqdm_notebook\nfrom PIL import Image, ImageFile\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import models\nfrom sklearn.model_selection import train_test_split\nfrom torchvision import transforms\nfrom skimage import io\nImageFile.LOAD_TRUNCATED_IMAGES = True\n\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Training Dataset\nwith open(r'/kaggle/input/iwildcam-2020-fgvc7/iwildcam2020_train_annotations.json') as train:\n    train_data = json.load(train)\n\n# Testing Dataset\nwith open(r'/kaggle/input/iwildcam-2020-fgvc7/iwildcam2020_test_information.json') as test:\n    test_data = json.load(test)\n    \nprint(\"Columns in training Json: \", train_data.keys())\nprint(\"Columns in testing Json:  \", test_data.keys())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data['categories']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_jpeg = glob.glob('../input/iwildcam-2020-fgvc7/train/*')\ntest_jpeg = glob.glob('../input/iwildcam-2020-fgvc7/test/*')\n\nprint(\"number of train jpeg data:\", len(train_jpeg))\nprint(\"number of test jpeg data:\", len(test_jpeg))\n\ntrain_jpeg[0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training Images"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(25, 16))\nfor i,im_path in enumerate(train_jpeg[:16]):\n    ax = fig.add_subplot(4, 4, i+1, xticks=[], yticks=[])\n    im = Image.open(im_path)\n    im = im.resize((360,270))\n    plt.imshow(im)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Testing Images"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(25, 16))\nfor i,im_path in enumerate(test_jpeg[:16]):\n    ax = fig.add_subplot(4, 4, i+1, xticks=[], yticks=[])\n    im = Image.open(im_path)\n    im = im.resize((360,270))\n    plt.imshow(im)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = pd.DataFrame({'id': [item['id'] for item in train_data['annotations']],\n                                'category_id': [item['category_id'] for item in train_data['annotations']],\n                                'image_id': [item['image_id'] for item in train_data['annotations']],\n                                'file_name': [item['file_name'] for item in train_data['images']]})\n\n\n# df_test = pd.DataFrame.from_records(test_data['images'])\n\ndf_train.to_csv('train_data.csv')\n# df_test.to_csv('test_data.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_image = pd.DataFrame.from_records(train_data['images'])\n# print(df_image.head())\n\nindices = []\nfor _id in df_image[df_image['location'] == 537]['id'].values:\n#     print(_id)\n    indices.append( df_train[ df_train['image_id'] == _id ].index )\n\nfor the_index in indices:\n    df_train = df_train.drop(df_train.index[the_index])\n    \ndf_train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Image.open('/kaggle/input/iwildcam-2020-fgvc7/train/'+df_train['file_name'][0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Remove the Unvalid or Corrupt Images from the training data****"},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\nfor index, i in enumerate(df_train['file_name']):\n    try:\n        Image.open('/kaggle/input/iwildcam-2020-fgvc7/train/' + i)\n    except:        \n        df_train.drop(df_train.loc[df_train['file_name']==i].index, inplace=True)\n        \ndf_train['category_id'] = df_train['category_id'].astype(str)\ndf_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"NUM_CLASSES = len(df_train['category_id'].unique())\nprint(NUM_CLASSES)\n\nnb_classes = len(train_data['categories'])\nprint(nb_classes)\n\nbatch_size = 32\nIMG_SIZE = 64\n\nNUM_EPOCHS = 10\n\nID_COLNAME = 'file_name'\nANSWER_COLNAME = 'category_id'\nTRAIN_IMGS_DIR = r'../input/iwildcam-2020-fgvc7/train/'\nTEST_IMGS_DIR = r'../input/iwildcam-2020-fgvc7/test/'\n\nCHANNELS = 3\n\nIMAGE_RESIZE = 299\nRESNET50_POOLING_AVERAGE = 'avg'\n\nSTEPS_PER_EPOCH_TRAINING = 10\nSTEPS_PER_EPOCH_VALIDATION = 10\n\nBATCH_SIZE_TRAINING = 100\nBATCH_SIZE_VALIDATION = 100\n\n# Using 1 to easily manage mapping between test_generator & prediction for submission preparation\nBATCH_SIZE_TESTING = 1\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_datagen=ImageDataGenerator(rescale=1./255\n    )\n\ntrain_generator=train_datagen.flow_from_dataframe(    \n    dataframe=df_train[:50000],    \n    directory=\"../input/iwildcam-2020-fgvc7/train\",\n    x_col=ID_COLNAME,\n    y_col=ANSWER_COLNAME,\n    batch_size=batch_size,\n    shuffle=True,\n    classes = [ str(i) for i in range(nb_classes-1)],\n    class_mode=\"categorical\",    \n    target_size=(IMAGE_RESIZE,IMAGE_RESIZE))\n\nvalid_datagen = ImageDataGenerator(rescale=1./255)\n\nvalid_generator=valid_datagen.flow_from_dataframe(    \n    dataframe=df_train[50000:80000],    \n    directory=\"../input/iwildcam-2020-fgvc7/train\",\n    x_col=ID_COLNAME,\n    y_col=ANSWER_COLNAME,\n    batch_size=batch_size,\n    shuffle=True,\n    classes = [ str(i) for i in range(nb_classes-1)],\n    class_mode=\"categorical\",  \n    target_size=(IMAGE_RESIZE,IMAGE_RESIZE))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# VGG16 Pretrained Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.applications.vgg19 import VGG19\nfrom keras.applications.resnet import ResNet50 \nfrom keras.applications.xception import Xception\nfrom keras.models import Sequential \nfrom keras.layers import Flatten, Dense, Dropout \nfrom keras.optimizers import Adam, SGD \nfrom keras.callbacks import EarlyStopping\n\nxception_model = Xception(weights=\"imagenet\", include_top=False, input_shape=(224,224,3))\n\nmodel = Sequential()\nmodel.add(xception_model)\nmodel.add(Flatten())\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(266, activation='softmax'))\nmodel.summary()\n\n# Compile model with Adam Optimizer\nmodel.compile(optimizer='adam',loss='categorical_crossentropy', metrics=['accuracy'])\nearly = EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=1, mode='auto')\n\nfit_history = model.fit_generator( \n    train_generator, \n    steps_per_epoch=STEPS_PER_EPOCH_TRAINING, \n    epochs = NUM_EPOCHS, \n    validation_data=valid_generator, \n    validation_steps=STEPS_PER_EPOCH_VALIDATION\n)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history_df = pd.DataFrame(fit_history.history) \nhistory_df[['loss', 'val_loss']].plot() \nhistory_df[['acc', 'val_acc']].plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import gc\ndel train_datagen, train_generator\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sam_sub_df = pd.read_csv('../input/iwildcam-2020-fgvc7/sample_submission.csv')\nsam_sub_df[\"file_name\"] = sam_sub_df[\"Id\"].map(lambda str : str + \".jpg\")\nsam_sub_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\ntest_generator = test_datagen.flow_from_dataframe(      \n    \n        dataframe=sam_sub_df,    \n    \n        directory = \"../input/iwildcam-2020-fgvc7/test\",    \n        x_col=\"file_name\",\n        target_size = (img_size,img_size),\n        batch_size = 1,\n        classes = [ str(i) for i in range(nb_classes)],\n        shuffle = False,\n        class_mode = None\n        )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ntest_generator.reset()\npredict=model.predict_generator(test_generator, steps = len(test_generator.filenames))\npredicted_class_indices=np.argmax(predict,axis=1)\nsam_sub_df[\"Category\"] = predicted_class_indices\nsam_sub_df = sam_sub_df.loc[:,[\"Id\", \"Category\"]]\nsam_sub_df.to_csv(\"submission.csv\",index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}